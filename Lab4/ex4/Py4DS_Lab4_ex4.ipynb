{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Py4DS_Lab4_ex4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t81WrR9xnwID",
        "outputId": "16328ac9-414f-4bff-bf8f-31d8711cbdd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIZlgm-c2w2w"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.cluster import KMeans, MeanShift, AgglomerativeClustering\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXAGP3065kws"
      },
      "source": [
        "'''\n",
        "Purpose: Count missing values and columns\n",
        "Parameters: \n",
        "  df_in: Dataframe input need to detect missing value\n",
        "Returns:\n",
        "  None\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0jDUSWTn_E1"
      },
      "source": [
        "def detect_missing_values(df_in):\n",
        "  df_miss = df_in.isnull().sum()\n",
        "  #print(df_miss)\n",
        "  df_miss = df_miss[df_miss>0]\n",
        "  print(\"There are {0} columns have missing values:\\n{1}\".format(len(df_miss),df_miss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_2mi1su6nCq"
      },
      "source": [
        "'''\n",
        "Purpose: Drop missing value\n",
        "Parameters: \n",
        "  df_in: Dataframe input need to drop\n",
        "  list_columns: List of columns need to detect and drop missing value\n",
        "Returns:\n",
        "  Dataframe after droping missing value\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUfUswbpuf_5"
      },
      "source": [
        "def drop_missing_values(df_in,list_columns):\n",
        "  df_out = df_in.copy()\n",
        "  #print(df_out)\n",
        "  #print(list_columns)\n",
        "  count_missing = 0\n",
        "  for column in list_columns:\n",
        "    try:\n",
        "      count_missing = count_missing + df_out[column].isnull().sum()\n",
        "      #print(\"Remove {0} missing values from {1} column\".format(df_out[column].isnull().sum(),column))\n",
        "      df_out = df_out[~df_out[column].isnull()].copy()\n",
        "    except:\n",
        "      print(\"Some thing error with column {0}\".format(column))\n",
        "  print(\"There are {0} values have been removed\".format(count_missing))\n",
        "  return df_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMn1gO7U7D4j"
      },
      "source": [
        "'''\n",
        "Purpose: Replace null values with most frequency value\n",
        "Parameters: \n",
        "  df_in: Dataframe input\n",
        "  list_columns: List of columns need to detect missing value and replace\n",
        "Returns:\n",
        "  Dataframe after replace null values with most frequency value\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjJMDgv55sDI"
      },
      "source": [
        "def impute_mode_value(df_in, list_columns):\n",
        "  df_out = df_in.copy()\n",
        "  count_missing = 0\n",
        "  for column in list_columns:\n",
        "    try:\n",
        "      count_missing = count_missing + df_out[column].isnull().sum()\n",
        "      #print(\"Impute {0} missing values from {1} column\".format(df_out[column].isnull().sum(),column))\n",
        "      mode_value = df_out[column].mode()[0]\n",
        "      df_out[column].fillna(mode_value,inplace = True)\n",
        "    except:\n",
        "      print(\"Some thing error with column {0}\".format(column))\n",
        "  print(\"There are {0} values have been imputed\".format(count_missing))\n",
        "  return df_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gJTGqYi7uZP"
      },
      "source": [
        "'''\n",
        "Purpose: Drop feature with highly correlation\n",
        "Parameters: \n",
        "  df_in: Dataframe input\n",
        "Returns:\n",
        "  df_in: If there ain't any highly correlation features\n",
        "  Dataframe: If there are highly correlation features, return dataframe after \n",
        "  remove feature\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhwT8HEeAuu1"
      },
      "source": [
        "def drop_highly_corr_feature(df_in):\n",
        "  df_out = df_in.copy()\n",
        "  corr = df_out.corr()\n",
        "  upper = corr.where(np.triu(np.ones(corr.shape),k=1).astype(np.bool))\n",
        "  to_drop = [column for column in upper.columns if any(abs(upper[column])>0.95)]\n",
        "  print(\"There are {0} highly correlation features has been removed\\n{1}\".format(len(to_drop),to_drop))\n",
        "  if (len(to_drop)==0):\n",
        "    return df_in\n",
        "  else:\n",
        "    return df_out.drop(to_drop,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKxB7ER-8WD7"
      },
      "source": [
        "'''\n",
        "Purpose: Drop feature with high null values\n",
        "Parameters: \n",
        "  df_in: Dataframe input\n",
        "  threshold: threshold to remove feature\n",
        "Returns:\n",
        "  Remove columns if percentage of nan greater than threshold. Return dataframe \n",
        "  after remove columns\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNmRiy_nL-Dr"
      },
      "source": [
        "def drop_high_nan_column(df_in,threshold = .8):\n",
        "  res = df_in.loc[:,df_in.isnull().mean()<threshold]\n",
        "  before = df_in.shape[1]\n",
        "  after = res.shape[1]\n",
        "  print(\"There are {0} columns have been removed because of high nan percentage\".format(before-after))\n",
        "  return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJD-wMdm9KrI"
      },
      "source": [
        "'''\n",
        "Purpose: Remove outlier\n",
        "Parameters: \n",
        "  df_in: Dataframe input\n",
        "Returns:\n",
        "  Dataframe after remove outlier\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbYB7JZwA9Cw"
      },
      "source": [
        "def remove_outlier(df_in):\n",
        "  Q1 = df_in.quantile(0.25)\n",
        "  Q3 = df_in.quantile(0.75)\n",
        "  IQR = Q3-Q1\n",
        "  outlier_condition = (df_in<(Q1-1.5*IQR))|(df_in>(Q3+1.5*IQR))\n",
        "  df_out = df_in[~outlier_condition]\n",
        "  before = df_in.isnull().sum().sum()\n",
        "  after = df_out.isnull().sum().sum()\n",
        "  print(\"There are {0} outliers have been removed\".format(after-before))\n",
        "  return df_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xudahwPW9VXy"
      },
      "source": [
        "'''\n",
        "Purpose: Generate next permutation\n",
        "Parameters: \n",
        "  a: A state\n",
        "Returns:\n",
        "  Next state of a\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72D0LDohLERB"
      },
      "source": [
        "def next_permutation(a):\n",
        "  for i in range(len(a)-2,-1,-1):\n",
        "    if (a[i]<a[i+1]):\n",
        "      break\n",
        "  if (a[i]>a[i+1]):\n",
        "      return False\n",
        "  for j in range(len(a)-1,-1,-1):\n",
        "      if (a[j]>a[i]):\n",
        "        break\n",
        "  a[i], a[j] = a[j], a[i]\n",
        "  a[i+1:] = reversed(a[i+1:])\n",
        "  return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZHxuX4F9im9"
      },
      "source": [
        "'''\n",
        "Purpose: Find label to transform y_pred to maximize accuracy with y_true\n",
        "Parameters: \n",
        "  y_true: Array of true label \n",
        "  y_pred: Array of predict label\n",
        "Returns:\n",
        "  Best label to tranform y_pred\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4moH69kQ5n-"
      },
      "source": [
        "def find_best_label(y_true, y_pred):\n",
        "  y_temp = y_true.copy()\n",
        "  yp_temp = y_pred.copy()\n",
        "  y_true = np.array(y_true)\n",
        "  y_pred = np.array(y_pred)\n",
        "  unique = np.unique(y_true)\n",
        "  #*********************************\n",
        "  #print(y_true)\n",
        "  #print(y_pred)\n",
        "  #*********************************\n",
        "  label = []\n",
        "  for i in range(0,len(unique)):\n",
        "    label.append(i)\n",
        "  max_count = 0\n",
        "  best_label = []\n",
        "  while (True):\n",
        "    counts = 0\n",
        "    for i in range(0,len(y_true)):\n",
        "      if (label[y_pred[i]] == y_true[i]):\n",
        "        counts = counts + 1\n",
        "    if (counts>max_count):\n",
        "      max_count = counts\n",
        "      best_label = label.copy()\n",
        "    if (not next_permutation(label)):\n",
        "      y_true = y_temp\n",
        "      return best_label\n",
        "  y_true = y_temp\n",
        "  y_pred = yp_temp\n",
        "  return best_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9ttRAoj-LpL"
      },
      "source": [
        "'''\n",
        "Purpose: Transform y to a new vector with label\n",
        "Parameters: \n",
        "  y: Array of label\n",
        "  label: Label to transform\n",
        "Returns:\n",
        "  Vector after transform\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_Huu1YFhmO1"
      },
      "source": [
        "def change_label(y,label):\n",
        "  res = []\n",
        "  for i in range(0,len(y)):\n",
        "    res.append(label[y[i]])\n",
        "  return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTTswoZG-exr"
      },
      "source": [
        "'''\n",
        "Purpose: Train data with Kmeans model then print accuracy\n",
        "Parameters: \n",
        "  X_train: Train set feature\n",
        "  y_train: Train set label\n",
        "  X_test: Test set feature\n",
        "  y_test: Test se label\n",
        "Returns:\n",
        "  None\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj1k9pXIiRso"
      },
      "source": [
        "def KMeans_model(X_train,y_train,X_test,y_test):\n",
        "  unique = np.unique(y_train)\n",
        "  cls = KMeans(n_clusters = len(unique), max_iter = len(y_train),random_state=42)\n",
        "  cls = cls.fit(X_train)\n",
        "  y_pred_train = np.array(cls.labels_)\n",
        "  label = find_best_label(y_train,y_pred_train)\n",
        "  y_pred_train = change_label(y_pred_train,label)\n",
        "  y_pred = cls.predict(X_test)\n",
        "  y_pred = change_label(y_pred,label)\n",
        "  print(\"Accuracy train: \",accuracy_score(y_train,y_pred_train))\n",
        "  print(\"Accuracy test: \", accuracy_score(y_test,y_pred))\n",
        "  print(\"Confusion_matrix: \", confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ60zJpu-53x"
      },
      "source": [
        "'''\n",
        "Purpose: Train data with Gaussian Mixture model then print accuracy\n",
        "Parameters: \n",
        "  X_train: Train set feature\n",
        "  y_train: Train set label\n",
        "  X_test: Test set feature\n",
        "  y_test: Test se label\n",
        "Returns:\n",
        "  None\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5IK7aZ0sCe9"
      },
      "source": [
        "def GaussianMixture_model(X_train,y_train,X_test,y_test):\n",
        "  unique = np.unique(y_train)\n",
        "  cls = GaussianMixture(n_components= len(unique), max_iter = len(y_train),random_state=42)\n",
        "  cls = cls.fit(X_train)\n",
        "  y_pred_train = np.array(cls.predict(X_train))\n",
        "  label = find_best_label(y_train,y_pred_train)\n",
        "  y_pred_train = change_label(y_pred_train,label)\n",
        "  y_pred = cls.predict(X_test)\n",
        "  y_pred = change_label(y_pred,label)\n",
        "  print(\"Accuracy train: \",accuracy_score(y_train,y_pred_train))\n",
        "  print(\"Accuracy test: \", accuracy_score(y_test,y_pred))\n",
        "  print(\"Confusion_matrix: \", confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krN7tXGY--Xx"
      },
      "source": [
        "'''\n",
        "Purpose: Train data with Agglomerative Clustering model then print accuracy\n",
        "Parameters: \n",
        "  X_train: Train set feature\n",
        "  y_train: Train set label\n",
        "  X_test: Test set feature\n",
        "  y_test: Test se label\n",
        "Returns:\n",
        "  None\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwMVf9NosfMC"
      },
      "source": [
        "def AgglomerativeClustering_model(X_train,y_train,X_test,y_test):\n",
        "  unique = np.unique(y_train)\n",
        "  cls = AgglomerativeClustering(n_clusters= len(unique))\n",
        "  cls = cls.fit(X_train)\n",
        "  y_pred_train = np.array(cls.labels_)\n",
        "  label = find_best_label(y_train,y_pred_train)\n",
        "  y_pred_train = change_label(y_pred_train,label)\n",
        "  y_pred = cls.fit_predict(X_test)\n",
        "  y_pred = change_label(y_pred,label)\n",
        "  print(\"Accuracy train: \",accuracy_score(y_train,y_pred_train))\n",
        "  print(\"Accuracy test: \", accuracy_score(y_test,y_pred))\n",
        "  print(\"Confusion_matrix: \", confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5XrWjW2pF3d"
      },
      "source": [
        "def main():\n",
        "  df = pd.read_csv('/content/drive/My Drive/Datasets/Py4DS_Lab1/xAPI-Edu-Data.csv')\n",
        "  #print(df)\n",
        "  '''\n",
        "  # Add some outlier value to datafram\n",
        "  n = int(np.random.rand()*100)\n",
        "  print(\"Create {0} outliers values\".format(n))\n",
        "  for k in range(0,n):\n",
        "    i = int(np.random.rand()*df.shape[0])\n",
        "    j = int(np.random.rand()*df.shape[1])\n",
        "    df.iloc[i,j] = -10000000\n",
        "  #'''\n",
        "  '''\n",
        "  # Add some random nan value to datafram\n",
        "  n = int(np.random.rand()*100)\n",
        "  print(\"Create {0} nan values\".format(n))\n",
        "  for k in range(0,n):\n",
        "    i = int(np.random.rand()*df.shape[0])\n",
        "    j = int(np.random.rand()*df.shape[1])\n",
        "    df.iloc[i,j] = np.nan\n",
        "  #'''\n",
        "  '''\n",
        "  # Add a nan columns to data frame\n",
        "  df['nan'] = np.full([df.shape[0]],np.nan)\n",
        "  #'''\n",
        "  detect_missing_values(df)\n",
        "  df = drop_highly_corr_feature(df)\n",
        "  df = remove_outlier(df)\n",
        "  df = drop_high_nan_column(df,0.8)\n",
        "  df = impute_mode_value(df,df.columns)\n",
        "  #df = drop_missing_values(df,df.columns)\n",
        "  print(df.dtypes)\n",
        "  for col in df.columns:\n",
        "    print(\"*\"*30)\n",
        "    if (not isinstance(df[col],(int,float))):\n",
        "      df[col] = LabelEncoder().fit_transform(df[col])\n",
        "    print(df[col].describe())\n",
        "  X = df.drop(['Class'],axis=1)\n",
        "  y = df['Class']\n",
        "  X_train, X_test, y_train, y_test  = train_test_split(X,y, test_size = 0.2,random_state=42)\n",
        "  print(\"*\"*40)\n",
        "  print(\"KMeans clustering model: \")\n",
        "  KMeans_model(X_train,y_train,X_test,y_test)\n",
        "  print(\"*\"*40)\n",
        "  print(\"Gaussian Mixture clustering model: \")\n",
        "  GaussianMixture_model(X_train,y_train,X_test,y_test)\n",
        "  print(\"*\"*40)\n",
        "  print(\"Agglomerative Clustering model: \")\n",
        "  AgglomerativeClustering_model(X_train,y_train,X_test,y_test)\n",
        "  #'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvRBbJW5pITK",
        "outputId": "1f61c7d3-4978-4112-903b-1a946b6fcb64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 0 columns have missing values:\n",
            "Series([], dtype: int64)\n",
            "There are 0 highly correlation feature has been removed\n",
            "[]\n",
            "There are 0 outliers have been removed\n",
            "There are 0 columns have been removed because of high nan percentage\n",
            "There are 0 values have been imputed\n",
            "gender                      object\n",
            "NationalITy                 object\n",
            "PlaceofBirth                object\n",
            "StageID                     object\n",
            "GradeID                     object\n",
            "SectionID                   object\n",
            "Topic                       object\n",
            "Semester                    object\n",
            "Relation                    object\n",
            "raisedhands                  int64\n",
            "VisITedResources             int64\n",
            "AnnouncementsView            int64\n",
            "Discussion                   int64\n",
            "ParentAnsweringSurvey       object\n",
            "ParentschoolSatisfaction    object\n",
            "StudentAbsenceDays          object\n",
            "Class                       object\n",
            "dtype: object\n",
            "******************************\n",
            "count    480.000000\n",
            "mean       0.635417\n",
            "std        0.481815\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        1.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n",
            "Name: gender, dtype: float64\n",
            "******************************\n",
            "count    480.000000\n",
            "mean       4.345833\n",
            "std        2.469265\n",
            "min        0.000000\n",
            "25%        3.000000\n",
            "50%        4.000000\n",
            "75%        4.000000\n",
            "max       13.000000\n",
            "Name: NationalITy, dtype: float64\n",
            "******************************\n",
            "count    480.000000\n",
            "mean       4.397917\n",
            "std        2.628334\n",
            "min        0.000000\n",
            "25%        3.000000\n",
            "50%        4.000000\n",
            "75%        4.000000\n",
            "max       13.000000\n",
            "Name: PlaceofBirth, dtype: float64\n",
            "******************************\n",
            "count    480.000000\n",
            "mean       1.345833\n",
            "std        0.603732\n",
            "min        0.000000\n",
            "25%        1.000000\n",
            "50%        1.000000\n",
            "75%        2.000000\n",
            "max        2.000000\n",
            "Name: StageID, dtype: float64\n",
            "******************************\n",
            "count    480.000000\n",
            "mean       2.906250\n",
            "std        2.464267\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        4.000000\n",
            "75%        5.000000\n",
            "max        9.000000\n",
            "Name: GradeID, dtype: float64\n",
            "******************************\n",
            "count    480.000000\n",
            "mean       0.472917\n",
            "std        0.612411\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        1.000000\n",
            "max        2.000000\n",
            "Name: SectionID, dtype: float64\n",
            "******************************\n",
            "count    480.000000\n",
            "mean       5.256250\n",
            "std        3.388388\n",
            "min        0.000000\n",
            "25%        3.000000\n",
            "50%        5.000000\n",
            "75%        7.000000\n",
            "max       11.000000\n",
            "Name: Topic, dtype: float64\n",
            "******************************\n",
            "count    480.000000\n",
            "mean       0.489583\n",
            "std        0.500413\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n",
            "Name: Semester, dtype: float64\n",
            "******************************\n",
            "count    480.000000\n",
            "mean       0.410417\n",
            "std        0.492423\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n",
            "Name: Relation, dtype: float64\n",
            "******************************\n",
            "count    480.000000\n",
            "mean      38.645833\n",
            "std       23.551560\n",
            "min        0.000000\n",
            "25%       15.750000\n",
            "50%       40.000000\n",
            "75%       59.000000\n",
            "max       81.000000\n",
            "Name: raisedhands, dtype: float64\n",
            "******************************\n",
            "count    480.000000\n",
            "mean      48.270833\n",
            "std       28.274556\n",
            "min        0.000000\n",
            "25%       20.000000\n",
            "50%       56.000000\n",
            "75%       73.000000\n",
            "max       88.000000\n",
            "Name: VisITedResources, dtype: float64\n",
            "******************************\n",
            "count    480.000000\n",
            "mean      36.364583\n",
            "std       24.815780\n",
            "min        0.000000\n",
            "25%       14.000000\n",
            "50%       32.000000\n",
            "75%       56.000000\n",
            "max       87.000000\n",
            "Name: AnnouncementsView, dtype: float64\n",
            "******************************\n",
            "count    480.000000\n",
            "mean      39.135417\n",
            "std       24.484847\n",
            "min        0.000000\n",
            "25%       18.000000\n",
            "50%       37.000000\n",
            "75%       62.000000\n",
            "max       89.000000\n",
            "Name: Discussion, dtype: float64\n",
            "******************************\n",
            "count    480.000000\n",
            "mean       0.562500\n",
            "std        0.496596\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        1.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n",
            "Name: ParentAnsweringSurvey, dtype: float64\n",
            "******************************\n",
            "count    480.000000\n",
            "mean       0.608333\n",
            "std        0.488632\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        1.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n",
            "Name: ParentschoolSatisfaction, dtype: float64\n",
            "******************************\n",
            "count    480.000000\n",
            "mean       0.602083\n",
            "std        0.489979\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        1.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n",
            "Name: StudentAbsenceDays, dtype: float64\n",
            "******************************\n",
            "count    480.000000\n",
            "mean       1.143750\n",
            "std        0.846312\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        1.000000\n",
            "75%        2.000000\n",
            "max        2.000000\n",
            "Name: Class, dtype: float64\n",
            "****************************************\n",
            "KMeans clustering model: \n",
            "Accuracy train:  0.5755208333333334\n",
            "Accuracy test:  0.6145833333333334\n",
            "Confusion_matrix:  [[12  1  9]\n",
            " [ 0 26  0]\n",
            " [13 14 21]]\n",
            "****************************************\n",
            "Gaussian Mixture clustering model: \n",
            "Accuracy train:  0.5598958333333334\n",
            "Accuracy test:  0.5416666666666666\n",
            "Confusion_matrix:  [[14  1  7]\n",
            " [ 0 23  3]\n",
            " [13 20 15]]\n",
            "****************************************\n",
            "Agglomerative Clustering model: \n",
            "Accuracy train:  0.6067708333333334\n",
            "Accuracy test:  0.46875\n",
            "Confusion_matrix:  [[11  0 11]\n",
            " [ 3 23  0]\n",
            " [28  9 11]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GC3Ufd2pgoV"
      },
      "source": [
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zT0FU--1dL-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}