{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Py4DS_Lab4_ex2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t81WrR9xnwID",
        "outputId": "7454310c-59e1-430d-e911-7f6f959997ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIZlgm-c2w2w"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.cluster import KMeans, MeanShift, AgglomerativeClustering\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXAGP3065kws"
      },
      "source": [
        "'''\n",
        "Purpose: Count missing values and columns\n",
        "Parameters: \n",
        "  df_in: Dataframe input need to detect missing value\n",
        "Returns:\n",
        "  None\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0jDUSWTn_E1"
      },
      "source": [
        "def detect_missing_values(df_in):\n",
        "  df_miss = df_in.isnull().sum()\n",
        "  #print(df_miss)\n",
        "  df_miss = df_miss[df_miss>0]\n",
        "  print(\"There are {0} columns have missing values:\\n{1}\".format(len(df_miss),df_miss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_2mi1su6nCq"
      },
      "source": [
        "'''\n",
        "Purpose: Drop missing value\n",
        "Parameters: \n",
        "  df_in: Dataframe input need to drop\n",
        "  list_columns: List of columns need to detect and drop missing value\n",
        "Returns:\n",
        "  Dataframe after droping missing value\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUfUswbpuf_5"
      },
      "source": [
        "def drop_missing_values(df_in,list_columns):\n",
        "  df_out = df_in.copy()\n",
        "  #print(df_out)\n",
        "  #print(list_columns)\n",
        "  count_missing = 0\n",
        "  for column in list_columns:\n",
        "    try:\n",
        "      count_missing = count_missing + df_out[column].isnull().sum()\n",
        "      #print(\"Remove {0} missing values from {1} column\".format(df_out[column].isnull().sum(),column))\n",
        "      df_out = df_out[~df_out[column].isnull()].copy()\n",
        "    except:\n",
        "      print(\"Some thing error with column {0}\".format(column))\n",
        "  print(\"There are {0} values have been removed\".format(count_missing))\n",
        "  return df_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMn1gO7U7D4j"
      },
      "source": [
        "'''\n",
        "Purpose: Replace null values with most frequency value\n",
        "Parameters: \n",
        "  df_in: Dataframe input\n",
        "  list_columns: List of columns need to detect missing value and replace\n",
        "Returns:\n",
        "  Dataframe after replace null values with most frequency value\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjJMDgv55sDI"
      },
      "source": [
        "def impute_mode_value(df_in, list_columns):\n",
        "  df_out = df_in.copy()\n",
        "  count_missing = 0\n",
        "  for column in list_columns:\n",
        "    try:\n",
        "      count_missing = count_missing + df_out[column].isnull().sum()\n",
        "      #print(\"Impute {0} missing values from {1} column\".format(df_out[column].isnull().sum(),column))\n",
        "      mode_value = df_out[column].mode()[0]\n",
        "      df_out[column].fillna(mode_value,inplace = True)\n",
        "    except:\n",
        "      print(\"Some thing error with column {0}\".format(column))\n",
        "  print(\"There are {0} values have been imputed\".format(count_missing))\n",
        "  return df_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gJTGqYi7uZP"
      },
      "source": [
        "'''\n",
        "Purpose: Drop feature with highly correlation\n",
        "Parameters: \n",
        "  df_in: Dataframe input\n",
        "Returns:\n",
        "  df_in: If there ain't any highly correlation features\n",
        "  Dataframe: If there are highly correlation features, return dataframe after \n",
        "  remove feature\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhwT8HEeAuu1"
      },
      "source": [
        "def drop_highly_corr_feature(df_in):\n",
        "  df_out = df_in.copy()\n",
        "  corr = df_out.corr()\n",
        "  upper = corr.where(np.triu(np.ones(corr.shape),k=1).astype(np.bool))\n",
        "  to_drop = [column for column in upper.columns if any(abs(upper[column])>0.95)]\n",
        "  print(\"There are {0} highly correlation feature has been removed\\n{1}\".format(len(to_drop),to_drop))\n",
        "  if (len(to_drop)==0):\n",
        "    return df_in\n",
        "  else:\n",
        "    return df_out.drop(to_drop,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKxB7ER-8WD7"
      },
      "source": [
        "'''\n",
        "Purpose: Drop feature with high null values\n",
        "Parameters: \n",
        "  df_in: Dataframe input\n",
        "  threshold: threshold to remove feature\n",
        "Returns:\n",
        "  Remove columns if percentage of nan greater than threshold. Return dataframe \n",
        "  after remove columns\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNmRiy_nL-Dr"
      },
      "source": [
        "def drop_high_nan_column(df_in,threshold = .8):\n",
        "  res = df_in.loc[:,df_in.isnull().mean()<threshold]\n",
        "  before = df_in.shape[1]\n",
        "  after = res.shape[1]\n",
        "  print(\"There are {0} columns have been removed because of high nan percentage\".format(before-after))\n",
        "  return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJD-wMdm9KrI"
      },
      "source": [
        "'''\n",
        "Purpose: Remove outlier\n",
        "Parameters: \n",
        "  df_in: Dataframe input\n",
        "Returns:\n",
        "  Dataframe after remove outlier\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbYB7JZwA9Cw"
      },
      "source": [
        "def remove_outlier(df_in):\n",
        "  Q1 = df_in.quantile(0.25)\n",
        "  Q3 = df_in.quantile(0.75)\n",
        "  IQR = Q3-Q1\n",
        "  outlier_condition = (df_in<(Q1-1.5*IQR))|(df_in>(Q3+1.5*IQR))\n",
        "  df_out = df_in[~outlier_condition]\n",
        "  before = df_in.isnull().sum().sum()\n",
        "  after = df_out.isnull().sum().sum()\n",
        "  print(\"There are {0} outliers have been removed\".format(after-before))\n",
        "  return df_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xudahwPW9VXy"
      },
      "source": [
        "'''\n",
        "Purpose: Generate next permutation\n",
        "Parameters: \n",
        "  a: A state\n",
        "Returns:\n",
        "  Next state of a\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72D0LDohLERB"
      },
      "source": [
        "def next_permutation(a):\n",
        "  for i in range(len(a)-2,-1,-1):\n",
        "    if (a[i]<a[i+1]):\n",
        "      break\n",
        "  if (a[i]>a[i+1]):\n",
        "      return False\n",
        "  for j in range(len(a)-1,-1,-1):\n",
        "      if (a[j]>a[i]):\n",
        "        break\n",
        "  a[i], a[j] = a[j], a[i]\n",
        "  a[i+1:] = reversed(a[i+1:])\n",
        "  return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZHxuX4F9im9"
      },
      "source": [
        "'''\n",
        "Purpose: Find label to transform y_pred to maximize accuracy with y_true\n",
        "Parameters: \n",
        "  y_true: Array of true label \n",
        "  y_pred: Array of predict label\n",
        "Returns:\n",
        "  Best label to tranform y_pred\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4moH69kQ5n-"
      },
      "source": [
        "def find_best_label(y_true, y_pred):\n",
        "  y_temp = y_true.copy()\n",
        "  yp_temp = y_pred.copy()\n",
        "  y_true = np.array(y_true)\n",
        "  y_pred = np.array(y_pred)\n",
        "  unique = np.unique(y_true)\n",
        "  #*********************************\n",
        "  #print(y_true)\n",
        "  #print(y_pred)\n",
        "  #*********************************\n",
        "  label = []\n",
        "  for i in range(0,len(unique)):\n",
        "    label.append(i)\n",
        "  max_count = 0\n",
        "  best_label = []\n",
        "  while (True):\n",
        "    counts = 0\n",
        "    for i in range(0,len(y_true)):\n",
        "      if (label[y_pred[i]] == y_true[i]):\n",
        "        counts = counts + 1\n",
        "    if (counts>max_count):\n",
        "      max_count = counts\n",
        "      best_label = label.copy()\n",
        "    if (not next_permutation(label)):\n",
        "      y_true = y_temp\n",
        "      return best_label\n",
        "  y_true = y_temp\n",
        "  y_pred = yp_temp\n",
        "  return best_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9ttRAoj-LpL"
      },
      "source": [
        "'''\n",
        "Purpose: Transform y to a new vector with label\n",
        "Parameters: \n",
        "  y: Array of label\n",
        "  label: Label to transform\n",
        "Returns:\n",
        "  Vector after transform\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_Huu1YFhmO1"
      },
      "source": [
        "def change_label(y,label):\n",
        "  res = []\n",
        "  for i in range(0,len(y)):\n",
        "    res.append(label[y[i]])\n",
        "  return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTTswoZG-exr"
      },
      "source": [
        "'''\n",
        "Purpose: Train data with Kmeans model then print accuracy\n",
        "Parameters: \n",
        "  X_train: Train set feature\n",
        "  y_train: Train set label\n",
        "  X_test: Test set feature\n",
        "  y_test: Test se label\n",
        "Returns:\n",
        "  None\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj1k9pXIiRso"
      },
      "source": [
        "def KMeans_model(X_train,y_train,X_test,y_test):\n",
        "  unique = np.unique(y_train)\n",
        "  cls = KMeans(n_clusters = len(unique), max_iter = len(y_train),random_state=42)\n",
        "  cls = cls.fit(X_train)\n",
        "  y_pred_train = np.array(cls.labels_)\n",
        "  label = find_best_label(y_train,y_pred_train)\n",
        "  y_pred_train = change_label(y_pred_train,label)\n",
        "  y_pred = cls.predict(X_test)\n",
        "  y_pred = change_label(y_pred,label)\n",
        "  print(\"Accuracy train: \",accuracy_score(y_train,y_pred_train))\n",
        "  print(\"Accuracy test: \", accuracy_score(y_test,y_pred))\n",
        "  print(\"Confusion_matrix: \", confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ60zJpu-53x"
      },
      "source": [
        "'''\n",
        "Purpose: Train data with Gaussian Mixture model then print accuracy\n",
        "Parameters: \n",
        "  X_train: Train set feature\n",
        "  y_train: Train set label\n",
        "  X_test: Test set feature\n",
        "  y_test: Test se label\n",
        "Returns:\n",
        "  None\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5IK7aZ0sCe9"
      },
      "source": [
        "def GaussianMixture_model(X_train,y_train,X_test,y_test):\n",
        "  unique = np.unique(y_train)\n",
        "  cls = GaussianMixture(n_components= len(unique), max_iter = len(y_train),random_state=42)\n",
        "  cls = cls.fit(X_train)\n",
        "  y_pred_train = np.array(cls.predict(X_train))\n",
        "  label = find_best_label(y_train,y_pred_train)\n",
        "  y_pred_train = change_label(y_pred_train,label)\n",
        "  y_pred = cls.predict(X_test)\n",
        "  y_pred = change_label(y_pred,label)\n",
        "  print(\"Accuracy train: \",accuracy_score(y_train,y_pred_train))\n",
        "  print(\"Accuracy test: \", accuracy_score(y_test,y_pred))\n",
        "  print(\"Confusion_matrix: \", confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krN7tXGY--Xx"
      },
      "source": [
        "'''\n",
        "Purpose: Train data with Agglomerative Clustering model then print accuracy\n",
        "Parameters: \n",
        "  X_train: Train set feature\n",
        "  y_train: Train set label\n",
        "  X_test: Test set feature\n",
        "  y_test: Test se label\n",
        "Returns:\n",
        "  None\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwMVf9NosfMC"
      },
      "source": [
        "def AgglomerativeClustering_model(X_train,y_train,X_test,y_test):\n",
        "  unique = np.unique(y_train)\n",
        "  cls = AgglomerativeClustering(n_clusters= len(unique))\n",
        "  cls = cls.fit(X_train)\n",
        "  y_pred_train = np.array(cls.labels_)\n",
        "  label = find_best_label(y_train,y_pred_train)\n",
        "  y_pred_train = change_label(y_pred_train,label)\n",
        "  y_pred = cls.fit_predict(X_test)\n",
        "  y_pred = change_label(y_pred,label)\n",
        "  print(\"Accuracy train: \",accuracy_score(y_train,y_pred_train))\n",
        "  print(\"Accuracy test: \", accuracy_score(y_test,y_pred))\n",
        "  print(\"Confusion_matrix: \", confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5XrWjW2pF3d"
      },
      "source": [
        "def main():\n",
        "  df = pd.read_csv('/content/drive/My Drive/Datasets/Py4DS_Lab1/diabetes.csv')\n",
        "  #print(df)\n",
        "  '''\n",
        "  # Add some outlier value to datafram\n",
        "  n = int(np.random.rand()*100)\n",
        "  print(\"Create {0} outliers values\".format(n))\n",
        "  for k in range(0,n):\n",
        "    i = int(np.random.rand()*df.shape[0])\n",
        "    j = int(np.random.rand()*df.shape[1])\n",
        "    df.iloc[i,j] = -10000000\n",
        "  #'''\n",
        "  '''\n",
        "  # Add some random nan value to datafram\n",
        "  n = int(np.random.rand()*100)\n",
        "  print(\"Create {0} nan values\".format(n))\n",
        "  for k in range(0,n):\n",
        "    i = int(np.random.rand()*df.shape[0])\n",
        "    j = int(np.random.rand()*df.shape[1])\n",
        "    df.iloc[i,j] = np.nan\n",
        "  #'''\n",
        "  '''\n",
        "  # Add a nan columns to data frame\n",
        "  df['nan'] = np.full([df.shape[0]],np.nan)\n",
        "  #'''\n",
        "  detect_missing_values(df)\n",
        "  df = drop_highly_corr_feature(df)\n",
        "  df = remove_outlier(df)\n",
        "  df = drop_high_nan_column(df,0.8)\n",
        "  #df = impute_mode_value(df,df.columns)\n",
        "  df = drop_missing_values(df,df.columns)\n",
        "  for col in df.columns:\n",
        "    print(\"*\"*30)\n",
        "    print(df[col].describe())\n",
        "  print(df.dtypes)\n",
        "  X = df.drop(['Outcome'],axis=1)\n",
        "  y = df['Outcome']\n",
        "  X_train, X_test, y_train, y_test  = train_test_split(X,y, test_size = 0.2,random_state=42)\n",
        "  print(\"*\"*40)\n",
        "  print(\"KMeans clustering model: \")\n",
        "  KMeans_model(X_train,y_train,X_test,y_test)\n",
        "  print(\"*\"*40)\n",
        "  print(\"Gaussian Mixture clustering model: \")\n",
        "  GaussianMixture_model(X_train,y_train,X_test,y_test)\n",
        "  print(\"*\"*40)\n",
        "  print(\"Agglomerative Clustering model: \")\n",
        "  AgglomerativeClustering_model(X_train,y_train,X_test,y_test)\n",
        "  #'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvRBbJW5pITK",
        "outputId": "cd7d98dd-3a16-48af-c0fa-d910d9ea4fb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 0 columns have missing values:\n",
            "Series([], dtype: int64)\n",
            "There are 0 highly correlation feature has been removed\n",
            "[]\n",
            "There are 146 outliers have been removed\n",
            "There are 0 columns have been removed because of high nan percentage\n",
            "There are 129 values have been removed\n",
            "******************************\n",
            "count    639.000000\n",
            "mean       3.804382\n",
            "std        3.260995\n",
            "min        0.000000\n",
            "25%        1.000000\n",
            "50%        3.000000\n",
            "75%        6.000000\n",
            "max       13.000000\n",
            "Name: Pregnancies, dtype: float64\n",
            "******************************\n",
            "count    639.000000\n",
            "mean     119.112676\n",
            "std       29.162175\n",
            "min       44.000000\n",
            "25%       99.000000\n",
            "50%      114.000000\n",
            "75%      137.000000\n",
            "max      198.000000\n",
            "Name: Glucose, dtype: float64\n",
            "******************************\n",
            "count    639.000000\n",
            "mean      72.120501\n",
            "std       11.348686\n",
            "min       38.000000\n",
            "25%       64.000000\n",
            "50%       72.000000\n",
            "75%       80.000000\n",
            "max      106.000000\n",
            "Name: BloodPressure, dtype: float64\n",
            "******************************\n",
            "count    639.000000\n",
            "mean      20.563380\n",
            "std       15.339991\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%       23.000000\n",
            "75%       32.000000\n",
            "max       60.000000\n",
            "Name: SkinThickness, dtype: float64\n",
            "******************************\n",
            "count    639.000000\n",
            "mean      65.931142\n",
            "std       79.569482\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%       37.000000\n",
            "75%      120.000000\n",
            "max      318.000000\n",
            "Name: Insulin, dtype: float64\n",
            "******************************\n",
            "count    639.00000\n",
            "mean      32.00579\n",
            "std        6.43397\n",
            "min       18.20000\n",
            "25%       27.30000\n",
            "50%       32.00000\n",
            "75%       35.95000\n",
            "max       50.00000\n",
            "Name: BMI, dtype: float64\n",
            "******************************\n",
            "count    639.000000\n",
            "mean       0.429177\n",
            "std        0.250957\n",
            "min        0.078000\n",
            "25%        0.242000\n",
            "50%        0.358000\n",
            "75%        0.586000\n",
            "max        1.191000\n",
            "Name: DiabetesPedigreeFunction, dtype: float64\n",
            "******************************\n",
            "count    639.000000\n",
            "mean      32.715180\n",
            "std       11.080651\n",
            "min       21.000000\n",
            "25%       24.000000\n",
            "50%       29.000000\n",
            "75%       40.000000\n",
            "max       66.000000\n",
            "Name: Age, dtype: float64\n",
            "******************************\n",
            "count    639.000000\n",
            "mean       0.312989\n",
            "std        0.464073\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n",
            "Name: Outcome, dtype: float64\n",
            "Pregnancies                 float64\n",
            "Glucose                     float64\n",
            "BloodPressure               float64\n",
            "SkinThickness               float64\n",
            "Insulin                     float64\n",
            "BMI                         float64\n",
            "DiabetesPedigreeFunction    float64\n",
            "Age                         float64\n",
            "Outcome                       int64\n",
            "dtype: object\n",
            "****************************************\n",
            "KMeans clustering model: \n",
            "Accuracy train:  0.6379647749510763\n",
            "Accuracy test:  0.578125\n",
            "Confusion_matrix:  [[64 28]\n",
            " [26 10]]\n",
            "****************************************\n",
            "Gaussian Mixture clustering model: \n",
            "Accuracy train:  0.5205479452054794\n",
            "Accuracy test:  0.609375\n",
            "Confusion_matrix:  [[53 39]\n",
            " [11 25]]\n",
            "****************************************\n",
            "Agglomerative Clustering model: \n",
            "Accuracy train:  0.5205479452054794\n",
            "Accuracy test:  0.6015625\n",
            "Confusion_matrix:  [[52 40]\n",
            " [11 25]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GC3Ufd2pgoV"
      },
      "source": [
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zT0FU--1dL-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}