{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Py4DS_Lab4_ex3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t81WrR9xnwID",
        "outputId": "844ae7c3-33a5-4c39-8cb1-cf87a213538a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIZlgm-c2w2w"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.cluster import KMeans, MeanShift, AgglomerativeClustering\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXAGP3065kws"
      },
      "source": [
        "'''\n",
        "Purpose: Count missing values and columns\n",
        "Parameters: \n",
        "  df_in: Dataframe input need to detect missing value\n",
        "Returns:\n",
        "  None\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0jDUSWTn_E1"
      },
      "source": [
        "def detect_missing_values(df_in):\n",
        "  df_miss = df_in.isnull().sum()\n",
        "  #print(df_miss)\n",
        "  df_miss = df_miss[df_miss>0]\n",
        "  print(\"There are {0} columns have missing values:\\n{1}\".format(len(df_miss),df_miss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_2mi1su6nCq"
      },
      "source": [
        "'''\n",
        "Purpose: Drop missing value\n",
        "Parameters: \n",
        "  df_in: Dataframe input need to drop\n",
        "  list_columns: List of columns need to detect and drop missing value\n",
        "Returns:\n",
        "  Dataframe after droping missing value\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUfUswbpuf_5"
      },
      "source": [
        "def drop_missing_values(df_in,list_columns):\n",
        "  df_out = df_in.copy()\n",
        "  #print(df_out)\n",
        "  #print(list_columns)\n",
        "  count_missing = 0\n",
        "  for column in list_columns:\n",
        "    try:\n",
        "      count_missing = count_missing + df_out[column].isnull().sum()\n",
        "      #print(\"Remove {0} missing values from {1} column\".format(df_out[column].isnull().sum(),column))\n",
        "      df_out = df_out[~df_out[column].isnull()].copy()\n",
        "    except:\n",
        "      print(\"Some thing error with column {0}\".format(column))\n",
        "  print(\"There are {0} values have been removed\".format(count_missing))\n",
        "  return df_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTCo5arj_Y0F"
      },
      "source": [
        "def drop_missing_values(df_in,list_columns):\n",
        "  df_out = df_in.copy()\n",
        "  #print(df_out)\n",
        "  #print(list_columns)\n",
        "  count_missing = 0\n",
        "  for column in list_columns:\n",
        "    try:\n",
        "      count_missing = count_missing + df_out[column].isnull().sum()\n",
        "      #print(\"Remove {0} missing values from {1} column\".format(df_out[column].isnull().sum(),column))\n",
        "      df_out = df_out[~df_out[column].isnull()].copy()\n",
        "    except:\n",
        "      print(\"Some thing error with column {0}\".format(column))\n",
        "  print(\"There are {0} values have been removed\".format(count_missing))\n",
        "  return df_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMn1gO7U7D4j"
      },
      "source": [
        "'''\n",
        "Purpose: Replace null values with most frequency value\n",
        "Parameters: \n",
        "  df_in: Dataframe input\n",
        "  list_columns: List of columns need to detect missing value and replace\n",
        "Returns:\n",
        "  Dataframe after replace null values with most frequency value\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjJMDgv55sDI"
      },
      "source": [
        "def impute_mode_value(df_in, list_columns):\n",
        "  df_out = df_in.copy()\n",
        "  count_missing = 0\n",
        "  for column in list_columns:\n",
        "    try:\n",
        "      count_missing = count_missing + df_out[column].isnull().sum()\n",
        "      #print(\"Impute {0} missing values from {1} column\".format(df_out[column].isnull().sum(),column))\n",
        "      mode_value = df_out[column].mode()[0]\n",
        "      df_out[column].fillna(mode_value,inplace = True)\n",
        "    except:\n",
        "      print(\"Some thing error with column {0}\".format(column))\n",
        "  print(\"There are {0} values have been imputed\".format(count_missing))\n",
        "  return df_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gJTGqYi7uZP"
      },
      "source": [
        "'''\n",
        "Purpose: Drop feature with highly correlation\n",
        "Parameters: \n",
        "  df_in: Dataframe input\n",
        "Returns:\n",
        "  df_in: If there ain't any highly correlation features\n",
        "  Dataframe: If there are highly correlation features, return dataframe after \n",
        "  remove feature\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhwT8HEeAuu1"
      },
      "source": [
        "def drop_highly_corr_feature(df_in):\n",
        "  df_out = df_in.copy()\n",
        "  corr = df_out.corr()\n",
        "  upper = corr.where(np.triu(np.ones(corr.shape),k=1).astype(np.bool))\n",
        "  to_drop = [column for column in upper.columns if any(abs(upper[column])>0.95)]\n",
        "  print(\"There are {0} highly correlation feature has been removed\\n{1}\".format(len(to_drop),to_drop))\n",
        "  if (len(to_drop)==0):\n",
        "    return df_in\n",
        "  else:\n",
        "    return df_out.drop(to_drop,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKxB7ER-8WD7"
      },
      "source": [
        "'''\n",
        "Purpose: Drop feature with high null values\n",
        "Parameters: \n",
        "  df_in: Dataframe input\n",
        "  threshold: threshold to remove feature\n",
        "Returns:\n",
        "  Remove columns if percentage of nan greater than threshold. Return dataframe \n",
        "  after remove columns\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNmRiy_nL-Dr"
      },
      "source": [
        "def drop_high_nan_column(df_in,threshold = .8):\n",
        "  res = df_in.loc[:,df_in.isnull().mean()<threshold]\n",
        "  before = df_in.shape[1]\n",
        "  after = res.shape[1]\n",
        "  print(\"There are {0} columns have been removed because of high nan percentage\".format(before-after))\n",
        "  return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJD-wMdm9KrI"
      },
      "source": [
        "'''\n",
        "Purpose: Remove outlier\n",
        "Parameters: \n",
        "  df_in: Dataframe input\n",
        "Returns:\n",
        "  Dataframe after remove outlier\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbYB7JZwA9Cw"
      },
      "source": [
        "def remove_outlier(df_in):\n",
        "  Q1 = df_in.quantile(0.25)\n",
        "  Q3 = df_in.quantile(0.75)\n",
        "  IQR = Q3-Q1\n",
        "  outlier_condition = (df_in<(Q1-1.5*IQR))|(df_in>(Q3+1.5*IQR))\n",
        "  df_out = df_in[~outlier_condition]\n",
        "  before = df_in.isnull().sum().sum()\n",
        "  after = df_out.isnull().sum().sum()\n",
        "  print(\"There are {0} outliers have been removed\".format(after-before))\n",
        "  return df_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xudahwPW9VXy"
      },
      "source": [
        "'''\n",
        "Purpose: Generate next permutation\n",
        "Parameters: \n",
        "  a: A state\n",
        "Returns:\n",
        "  Next state of a\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72D0LDohLERB"
      },
      "source": [
        "def next_permutation(a):\n",
        "  for i in range(len(a)-2,-1,-1):\n",
        "    if (a[i]<a[i+1]):\n",
        "      break\n",
        "  if (a[i]>a[i+1]):\n",
        "      return False\n",
        "  for j in range(len(a)-1,-1,-1):\n",
        "      if (a[j]>a[i]):\n",
        "        break\n",
        "  a[i], a[j] = a[j], a[i]\n",
        "  a[i+1:] = reversed(a[i+1:])\n",
        "  return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZHxuX4F9im9"
      },
      "source": [
        "'''\n",
        "Purpose: Find label to transform y_pred to maximize accuracy with y_true\n",
        "Parameters: \n",
        "  y_true: Array of true label \n",
        "  y_pred: Array of predict label\n",
        "Returns:\n",
        "  Best label to tranform y_pred\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4moH69kQ5n-"
      },
      "source": [
        "def find_best_label(y_true, y_pred):\n",
        "  y_temp = y_true.copy()\n",
        "  yp_temp = y_pred.copy()\n",
        "  y_true = np.array(y_true)\n",
        "  y_pred = np.array(y_pred)\n",
        "  unique = np.unique(y_true)\n",
        "  #*********************************\n",
        "  #print(y_true)\n",
        "  #print(y_pred)\n",
        "  #*********************************\n",
        "  label = []\n",
        "  for i in range(0,len(unique)):\n",
        "    label.append(i)\n",
        "  max_count = 0\n",
        "  best_label = []\n",
        "  while (True):\n",
        "    counts = 0\n",
        "    for i in range(0,len(y_true)):\n",
        "      if (label[y_pred[i]] == y_true[i]):\n",
        "        counts = counts + 1\n",
        "    if (counts>max_count):\n",
        "      max_count = counts\n",
        "      best_label = label.copy()\n",
        "    if (not next_permutation(label)):\n",
        "      y_true = y_temp\n",
        "      return best_label\n",
        "  y_true = y_temp\n",
        "  y_pred = yp_temp\n",
        "  return best_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9ttRAoj-LpL"
      },
      "source": [
        "'''\n",
        "Purpose: Transform y to a new vector with label\n",
        "Parameters: \n",
        "  y: Array of label\n",
        "  label: Label to transform\n",
        "Returns:\n",
        "  Vector after transform\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_Huu1YFhmO1"
      },
      "source": [
        "def change_label(y,label):\n",
        "  res = []\n",
        "  for i in range(0,len(y)):\n",
        "    res.append(label[y[i]])\n",
        "  return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTTswoZG-exr"
      },
      "source": [
        "'''\n",
        "Purpose: Train data with Kmeans model then print accuracy\n",
        "Parameters: \n",
        "  X_train: Train set feature\n",
        "  y_train: Train set label\n",
        "  X_test: Test set feature\n",
        "  y_test: Test se label\n",
        "Returns:\n",
        "  None\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj1k9pXIiRso"
      },
      "source": [
        "def KMeans_model(X_train,y_train,X_test,y_test):\n",
        "  unique = np.unique(y_train)\n",
        "  cls = KMeans(n_clusters = len(unique), max_iter = len(y_train),random_state=42)\n",
        "  cls = cls.fit(X_train)\n",
        "  y_pred_train = np.array(cls.labels_)\n",
        "  label = find_best_label(y_train,y_pred_train)\n",
        "  y_pred_train = change_label(y_pred_train,label)\n",
        "  y_pred = cls.predict(X_test)\n",
        "  y_pred = change_label(y_pred,label)\n",
        "  print(\"Accuracy train: \",accuracy_score(y_train,y_pred_train))\n",
        "  print(\"Accuracy test: \", accuracy_score(y_test,y_pred))\n",
        "  print(\"Confusion_matrix: \", confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ60zJpu-53x"
      },
      "source": [
        "'''\n",
        "Purpose: Train data with Gaussian Mixture model then print accuracy\n",
        "Parameters: \n",
        "  X_train: Train set feature\n",
        "  y_train: Train set label\n",
        "  X_test: Test set feature\n",
        "  y_test: Test se label\n",
        "Returns:\n",
        "  None\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5IK7aZ0sCe9"
      },
      "source": [
        "def GaussianMixture_model(X_train,y_train,X_test,y_test):\n",
        "  unique = np.unique(y_train)\n",
        "  cls = GaussianMixture(n_components= len(unique), max_iter = len(y_train),random_state=42)\n",
        "  cls = cls.fit(X_train)\n",
        "  y_pred_train = np.array(cls.predict(X_train))\n",
        "  label = find_best_label(y_train,y_pred_train)\n",
        "  y_pred_train = change_label(y_pred_train,label)\n",
        "  y_pred = cls.predict(X_test)\n",
        "  y_pred = change_label(y_pred,label)\n",
        "  print(\"Accuracy train: \",accuracy_score(y_train,y_pred_train))\n",
        "  print(\"Accuracy test: \", accuracy_score(y_test,y_pred))\n",
        "  print(\"Confusion_matrix: \", confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krN7tXGY--Xx"
      },
      "source": [
        "'''\n",
        "Purpose: Train data with Agglomerative Clustering model then print accuracy\n",
        "Parameters: \n",
        "  X_train: Train set feature\n",
        "  y_train: Train set label\n",
        "  X_test: Test set feature\n",
        "  y_test: Test se label\n",
        "Returns:\n",
        "  None\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwMVf9NosfMC"
      },
      "source": [
        "def AgglomerativeClustering_model(X_train,y_train,X_test,y_test):\n",
        "  unique = np.unique(y_train)\n",
        "  cls = AgglomerativeClustering(n_clusters= len(unique))\n",
        "  cls = cls.fit(X_train)\n",
        "  y_pred_train = np.array(cls.labels_)\n",
        "  label = find_best_label(y_train,y_pred_train)\n",
        "  y_pred_train = change_label(y_pred_train,label)\n",
        "  y_pred = cls.fit_predict(X_test)\n",
        "  y_pred = change_label(y_pred,label)\n",
        "  print(\"Accuracy train: \",accuracy_score(y_train,y_pred_train))\n",
        "  print(\"Accuracy test: \", accuracy_score(y_test,y_pred))\n",
        "  print(\"Confusion_matrix: \", confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5XrWjW2pF3d"
      },
      "source": [
        "def main():\n",
        "  df = pd.read_csv('/content/drive/My Drive/Datasets/Py4DS_Lab1/mushrooms.csv')\n",
        "  #print(df)\n",
        "  '''\n",
        "  # Add some outlier value to datafram\n",
        "  n = int(np.random.rand()*100)\n",
        "  print(\"Create {0} outliers values\".format(n))\n",
        "  for k in range(0,n):\n",
        "    i = int(np.random.rand()*df.shape[0])\n",
        "    j = int(np.random.rand()*df.shape[1])\n",
        "    df.iloc[i,j] = -10000000\n",
        "  #'''\n",
        "  '''\n",
        "  # Add some random nan value to datafram\n",
        "  n = int(np.random.rand()*100)\n",
        "  print(\"Create {0} nan values\".format(n))\n",
        "  for k in range(0,n):\n",
        "    i = int(np.random.rand()*df.shape[0])\n",
        "    j = int(np.random.rand()*df.shape[1])\n",
        "    df.iloc[i,j] = np.nan\n",
        "  #'''\n",
        "  '''\n",
        "  # Add a nan columns to data frame\n",
        "  df['nan'] = np.full([df.shape[0]],np.nan)\n",
        "  #'''\n",
        "  detect_missing_values(df)\n",
        "  #df = drop_highly_corr_feature(df)\n",
        "  #df = remove_outlier(df)\n",
        "  df = drop_high_nan_column(df,0.8)\n",
        "  #df = impute_mode_value(df,df.columns)\n",
        "  df = drop_missing_values(df,df.columns)\n",
        "  df=df.drop('veil-type',axis = 1)\n",
        "  for col in df.columns:\n",
        "    print(\"*\"*30)\n",
        "    print(df[col].describe())\n",
        "    df[col] = LabelEncoder().fit_transform(df[col])\n",
        "  print(df.dtypes)\n",
        "  X = df.drop(['class'],axis=1)\n",
        "  y = df['class']\n",
        "  X_train, X_test, y_train, y_test  = train_test_split(X,y, test_size = 0.2,random_state=42)\n",
        "  print(\"*\"*40)\n",
        "  print(\"KMeans clustering model: \")\n",
        "  KMeans_model(X_train,y_train,X_test,y_test)\n",
        "  print(\"*\"*40)\n",
        "  print(\"Gaussian Mixture clustering model: \")\n",
        "  GaussianMixture_model(X_train,y_train,X_test,y_test)\n",
        "  print(\"*\"*40)\n",
        "  print(\"Agglomerative Clustering model: \")\n",
        "  AgglomerativeClustering_model(X_train,y_train,X_test,y_test)\n",
        "  #'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvRBbJW5pITK",
        "outputId": "ceeedd56-6949-4e16-d425-1ebf2ec75d7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 0 columns have missing values:\n",
            "Series([], dtype: int64)\n",
            "There are 0 columns have been removed because of high nan percentage\n",
            "There are 0 values have been removed\n",
            "******************************\n",
            "count     8124\n",
            "unique       2\n",
            "top          e\n",
            "freq      4208\n",
            "Name: class, dtype: object\n",
            "******************************\n",
            "count     8124\n",
            "unique       6\n",
            "top          x\n",
            "freq      3656\n",
            "Name: cap-shape, dtype: object\n",
            "******************************\n",
            "count     8124\n",
            "unique       4\n",
            "top          y\n",
            "freq      3244\n",
            "Name: cap-surface, dtype: object\n",
            "******************************\n",
            "count     8124\n",
            "unique      10\n",
            "top          n\n",
            "freq      2284\n",
            "Name: cap-color, dtype: object\n",
            "******************************\n",
            "count     8124\n",
            "unique       2\n",
            "top          f\n",
            "freq      4748\n",
            "Name: bruises, dtype: object\n",
            "******************************\n",
            "count     8124\n",
            "unique       9\n",
            "top          n\n",
            "freq      3528\n",
            "Name: odor, dtype: object\n",
            "******************************\n",
            "count     8124\n",
            "unique       2\n",
            "top          f\n",
            "freq      7914\n",
            "Name: gill-attachment, dtype: object\n",
            "******************************\n",
            "count     8124\n",
            "unique       2\n",
            "top          c\n",
            "freq      6812\n",
            "Name: gill-spacing, dtype: object\n",
            "******************************\n",
            "count     8124\n",
            "unique       2\n",
            "top          b\n",
            "freq      5612\n",
            "Name: gill-size, dtype: object\n",
            "******************************\n",
            "count     8124\n",
            "unique      12\n",
            "top          b\n",
            "freq      1728\n",
            "Name: gill-color, dtype: object\n",
            "******************************\n",
            "count     8124\n",
            "unique       2\n",
            "top          t\n",
            "freq      4608\n",
            "Name: stalk-shape, dtype: object\n",
            "******************************\n",
            "count     8124\n",
            "unique       5\n",
            "top          b\n",
            "freq      3776\n",
            "Name: stalk-root, dtype: object\n",
            "******************************\n",
            "count     8124\n",
            "unique       4\n",
            "top          s\n",
            "freq      5176\n",
            "Name: stalk-surface-above-ring, dtype: object\n",
            "******************************\n",
            "count     8124\n",
            "unique       4\n",
            "top          s\n",
            "freq      4936\n",
            "Name: stalk-surface-below-ring, dtype: object\n",
            "******************************\n",
            "count     8124\n",
            "unique       9\n",
            "top          w\n",
            "freq      4464\n",
            "Name: stalk-color-above-ring, dtype: object\n",
            "******************************\n",
            "count     8124\n",
            "unique       9\n",
            "top          w\n",
            "freq      4384\n",
            "Name: stalk-color-below-ring, dtype: object\n",
            "******************************\n",
            "count     8124\n",
            "unique       4\n",
            "top          w\n",
            "freq      7924\n",
            "Name: veil-color, dtype: object\n",
            "******************************\n",
            "count     8124\n",
            "unique       3\n",
            "top          o\n",
            "freq      7488\n",
            "Name: ring-number, dtype: object\n",
            "******************************\n",
            "count     8124\n",
            "unique       5\n",
            "top          p\n",
            "freq      3968\n",
            "Name: ring-type, dtype: object\n",
            "******************************\n",
            "count     8124\n",
            "unique       9\n",
            "top          w\n",
            "freq      2388\n",
            "Name: spore-print-color, dtype: object\n",
            "******************************\n",
            "count     8124\n",
            "unique       6\n",
            "top          v\n",
            "freq      4040\n",
            "Name: population, dtype: object\n",
            "******************************\n",
            "count     8124\n",
            "unique       7\n",
            "top          d\n",
            "freq      3148\n",
            "Name: habitat, dtype: object\n",
            "class                       int64\n",
            "cap-shape                   int64\n",
            "cap-surface                 int64\n",
            "cap-color                   int64\n",
            "bruises                     int64\n",
            "odor                        int64\n",
            "gill-attachment             int64\n",
            "gill-spacing                int64\n",
            "gill-size                   int64\n",
            "gill-color                  int64\n",
            "stalk-shape                 int64\n",
            "stalk-root                  int64\n",
            "stalk-surface-above-ring    int64\n",
            "stalk-surface-below-ring    int64\n",
            "stalk-color-above-ring      int64\n",
            "stalk-color-below-ring      int64\n",
            "veil-color                  int64\n",
            "ring-number                 int64\n",
            "ring-type                   int64\n",
            "spore-print-color           int64\n",
            "population                  int64\n",
            "habitat                     int64\n",
            "dtype: object\n",
            "****************************************\n",
            "KMeans clustering model: \n",
            "Accuracy train:  0.7102631174026773\n",
            "Accuracy test:  0.704\n",
            "Confusion_matrix:  [[811  32]\n",
            " [449 333]]\n",
            "****************************************\n",
            "Gaussian Mixture clustering model: \n",
            "Accuracy train:  0.71118633635944\n",
            "Accuracy test:  0.7052307692307692\n",
            "Confusion_matrix:  [[811  32]\n",
            " [447 335]]\n",
            "****************************************\n",
            "Agglomerative Clustering model: \n",
            "Accuracy train:  0.7067241114017541\n",
            "Accuracy test:  0.7052307692307692\n",
            "Confusion_matrix:  [[811  32]\n",
            " [447 335]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GC3Ufd2pgoV"
      },
      "source": [
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zT0FU--1dL-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}